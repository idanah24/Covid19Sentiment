{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('owid-covid-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing out relevant countries and information\n",
    "data = data[(data['location'] == 'United States') | (data['location'] == 'United Kingdom') | (data['location'] == 'Canada') | (data['location'] == 'Australia')]\n",
    "data = data[['location', 'date', 'total_cases', 'total_deaths', 'population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating cases and deaths by population size\n",
    "data['cases_by_pop'] = data.apply(lambda row: row['total_cases'] / row['population'], axis='columns')\n",
    "data['deaths_by_pop'] = data.apply(lambda row: row['total_deaths'] / row['population'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering relevant data by country\n",
    "usa_pop_tweets = pd.read_csv('usa_pop_tweets.csv').drop_duplicates()\n",
    "usa_inf_tweets = pd.read_csv('usa_inf_tweets.csv').drop_duplicates()\n",
    "usa_covid = data[data['location'] == 'United States']\n",
    "\n",
    "uk_pop_tweets = pd.read_csv('uk_pop_tweets.csv').drop_duplicates()\n",
    "uk_inf_tweets = pd.read_csv('uk_inf_tweets.csv').drop_duplicates()\n",
    "uk_covid = data[data['location'] == 'United Kingdom']\n",
    "\n",
    "canada_pop_tweets = pd.read_csv('canada_pop_tweets.csv').drop_duplicates()\n",
    "canada_inf_tweets = pd.read_csv('canada_inf_tweets.csv').drop_duplicates()\n",
    "canada_covid = data[data['location'] == 'Canada']\n",
    "\n",
    "australia_pop_tweets = pd.read_csv('australia_pop_tweets.csv').drop_duplicates()\n",
    "australia_inf_tweets = pd.read_csv('australia_inf_tweets.csv').drop_duplicates()\n",
    "australia_covid = data[data['location'] == 'Australia']\n",
    "\n",
    "countries = {\n",
    "    'United States': {'covid': usa_covid, 'inf': usa_inf_tweets, 'pop': usa_pop_tweets},\n",
    "    'United Kingdom': {'covid': uk_covid, 'inf': uk_inf_tweets, 'pop': uk_pop_tweets},\n",
    "    'Canada': {'covid': canada_covid, 'inf': canada_inf_tweets, 'pop': canada_pop_tweets},\n",
    "    'Australia': {'covid': australia_covid, 'inf': australia_inf_tweets, 'pop': australia_pop_tweets}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tweets(tweets, source):\n",
    "    \"\"\"This function takes in a dataframe with tweets, calculates average sentiment scores for each day\"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment = tweets['tweet'].map(lambda tweet: analyzer.polarity_scores(tweet))\n",
    "    tweets['neg'] = sentiment.map(lambda res: res['neg'])\n",
    "    tweets['neu'] = sentiment.map(lambda res: res['neu'])\n",
    "    tweets['pos'] = sentiment.map(lambda res: res['pos'])\n",
    "    neg = source + \"_neg_avg\"\n",
    "    neu = source + \"_neu_avg\"\n",
    "    pos = source + \"_pos_avg\"\n",
    "    amount = source + \"_amount\"\n",
    "    return tweets.groupby(by='date').apply(lambda df: pd.Series({neg: df['neg'].mean(), neu: df['neu'].mean(), pos: df['pos'].mean(), amount: df.shape[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(covid_data, overall_sentiment, inf_sentiment):\n",
    "    \"\"\"This function merges all data of a given country\"\"\"\n",
    "    merged_sentiment = pd.merge(overall_sentiment, inf_sentiment, left_index=True, right_index=True)\n",
    "    return pd.merge(covid_data, merged_sentiment, left_on='date', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data = None\n",
    "for country in countries.keys():\n",
    "    if ready_data is None:\n",
    "        ready_data = join_data(countries[country]['covid'], analyze_tweets(countries[country]['inf'], 'inf'), analyze_tweets(countries[country]['pop'], 'pop'))\n",
    "    else:\n",
    "        ready_data = ready_data.append(join_data(countries[country]['covid'], analyze_tweets(countries[country]['inf'], 'inf'), analyze_tweets(countries[country]['pop'], 'pop')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_data.to_csv('ready_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
